Args in experiment:
Namespace(W=0.1, activation='gelu', affine=0, alpha1=0.1, alpha2=0.1, alpha3=0.1, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=128, d_layers=1, d_model=16, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.3, e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='VanDerPol', model_id='336_192', moving_avg=25, n_heads=4, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 336_192_VanDerPol_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
Epoch: 1 cost time: 2.0443732738494873
Epoch: 1, Steps: 63 | Train Loss: 1.0620104 Vali Loss: 1.5932332 Test Loss: 1.1813115
Validation loss decreased (inf --> 1.593233).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.7416036128997803
Epoch: 2, Steps: 63 | Train Loss: 1.0193338 Vali Loss: 1.5270976 Test Loss: 1.1393729
Validation loss decreased (1.593233 --> 1.527098).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 1.8058719635009766
Epoch: 3, Steps: 63 | Train Loss: 0.9886984 Vali Loss: 1.5070238 Test Loss: 1.1408370
Validation loss decreased (1.527098 --> 1.507024).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 1.758199691772461
Epoch: 4, Steps: 63 | Train Loss: 0.9639302 Vali Loss: 1.4843208 Test Loss: 1.1433907
Validation loss decreased (1.507024 --> 1.484321).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.1360747814178467
Epoch: 5, Steps: 63 | Train Loss: 0.9369253 Vali Loss: 1.4587984 Test Loss: 1.1408033
Validation loss decreased (1.484321 --> 1.458798).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 1.8267629146575928
Epoch: 6, Steps: 63 | Train Loss: 0.9096789 Vali Loss: 1.4303573 Test Loss: 1.1362952
Validation loss decreased (1.458798 --> 1.430357).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.1334359645843506
Epoch: 7, Steps: 63 | Train Loss: 0.8841155 Vali Loss: 1.4041891 Test Loss: 1.1357157
Validation loss decreased (1.430357 --> 1.404189).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.172840118408203
Epoch: 8, Steps: 63 | Train Loss: 0.8610196 Vali Loss: 1.3797891 Test Loss: 1.1338460
Validation loss decreased (1.404189 --> 1.379789).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 1.9128997325897217
Epoch: 9, Steps: 63 | Train Loss: 0.8414870 Vali Loss: 1.3583529 Test Loss: 1.1293643
Validation loss decreased (1.379789 --> 1.358353).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.1470980644226074
Epoch: 10, Steps: 63 | Train Loss: 0.8245334 Vali Loss: 1.3431565 Test Loss: 1.1313918
Validation loss decreased (1.358353 --> 1.343156).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.13012957572937
Epoch: 11, Steps: 63 | Train Loss: 0.8109105 Vali Loss: 1.3292354 Test Loss: 1.1272202
Validation loss decreased (1.343156 --> 1.329235).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.0499424934387207
Epoch: 12, Steps: 63 | Train Loss: 0.7987877 Vali Loss: 1.3175915 Test Loss: 1.1252953
Validation loss decreased (1.329235 --> 1.317592).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.378626585006714
Epoch: 13, Steps: 63 | Train Loss: 0.7885290 Vali Loss: 1.3076068 Test Loss: 1.1243414
Validation loss decreased (1.317592 --> 1.307607).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.1659038066864014
Epoch: 14, Steps: 63 | Train Loss: 0.7797595 Vali Loss: 1.2988627 Test Loss: 1.1204852
Validation loss decreased (1.307607 --> 1.298863).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.264618396759033
Epoch: 15, Steps: 63 | Train Loss: 0.7729564 Vali Loss: 1.2918829 Test Loss: 1.1200885
Validation loss decreased (1.298863 --> 1.291883).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.058680772781372
Epoch: 16, Steps: 63 | Train Loss: 0.7656200 Vali Loss: 1.2854936 Test Loss: 1.1182543
Validation loss decreased (1.291883 --> 1.285494).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.2066125869750977
Epoch: 17, Steps: 63 | Train Loss: 0.7597817 Vali Loss: 1.2798797 Test Loss: 1.1172096
Validation loss decreased (1.285494 --> 1.279880).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.1846563816070557
Epoch: 18, Steps: 63 | Train Loss: 0.7544712 Vali Loss: 1.2745275 Test Loss: 1.1155741
Validation loss decreased (1.279880 --> 1.274528).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 1.8532702922821045
Epoch: 19, Steps: 63 | Train Loss: 0.7497789 Vali Loss: 1.2703612 Test Loss: 1.1141751
Validation loss decreased (1.274528 --> 1.270361).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 1.8330752849578857
Epoch: 20, Steps: 63 | Train Loss: 0.7459507 Vali Loss: 1.2672330 Test Loss: 1.1136452
Validation loss decreased (1.270361 --> 1.267233).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 1.9155473709106445
Epoch: 21, Steps: 63 | Train Loss: 0.7424423 Vali Loss: 1.2641382 Test Loss: 1.1133134
Validation loss decreased (1.267233 --> 1.264138).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 1.8157308101654053
Epoch: 22, Steps: 63 | Train Loss: 0.7385893 Vali Loss: 1.2605994 Test Loss: 1.1114820
Validation loss decreased (1.264138 --> 1.260599).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.226825475692749
Epoch: 23, Steps: 63 | Train Loss: 0.7359114 Vali Loss: 1.2581478 Test Loss: 1.1117579
Validation loss decreased (1.260599 --> 1.258148).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.2762258052825928
Epoch: 24, Steps: 63 | Train Loss: 0.7334839 Vali Loss: 1.2565711 Test Loss: 1.1108041
Validation loss decreased (1.258148 --> 1.256571).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.1103882789611816
Epoch: 25, Steps: 63 | Train Loss: 0.7314929 Vali Loss: 1.2539731 Test Loss: 1.1102475
Validation loss decreased (1.256571 --> 1.253973).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.0926785469055176
Epoch: 26, Steps: 63 | Train Loss: 0.7290116 Vali Loss: 1.2526715 Test Loss: 1.1095923
Validation loss decreased (1.253973 --> 1.252671).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 1.7801084518432617
Epoch: 27, Steps: 63 | Train Loss: 0.7273061 Vali Loss: 1.2510827 Test Loss: 1.1090925
Validation loss decreased (1.252671 --> 1.251083).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.253631830215454
Epoch: 28, Steps: 63 | Train Loss: 0.7255806 Vali Loss: 1.2498940 Test Loss: 1.1086215
Validation loss decreased (1.251083 --> 1.249894).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.206005811691284
Epoch: 29, Steps: 63 | Train Loss: 0.7245961 Vali Loss: 1.2481537 Test Loss: 1.1073611
Validation loss decreased (1.249894 --> 1.248154).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 1.9734444618225098
Epoch: 30, Steps: 63 | Train Loss: 0.7234479 Vali Loss: 1.2475274 Test Loss: 1.1081374
Validation loss decreased (1.248154 --> 1.247527).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.2042484283447266
Epoch: 31, Steps: 63 | Train Loss: 0.7216422 Vali Loss: 1.2462019 Test Loss: 1.1079670
Validation loss decreased (1.247527 --> 1.246202).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.147919178009033
Epoch: 32, Steps: 63 | Train Loss: 0.7209124 Vali Loss: 1.2452049 Test Loss: 1.1072888
Validation loss decreased (1.246202 --> 1.245205).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.018758535385132
Epoch: 33, Steps: 63 | Train Loss: 0.7199133 Vali Loss: 1.2447193 Test Loss: 1.1072657
Validation loss decreased (1.245205 --> 1.244719).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.070810556411743
Epoch: 34, Steps: 63 | Train Loss: 0.7192240 Vali Loss: 1.2439719 Test Loss: 1.1067523
Validation loss decreased (1.244719 --> 1.243972).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 1.833303451538086
Epoch: 35, Steps: 63 | Train Loss: 0.7183060 Vali Loss: 1.2434915 Test Loss: 1.1070048
Validation loss decreased (1.243972 --> 1.243492).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 1.9807438850402832
Epoch: 36, Steps: 63 | Train Loss: 0.7173517 Vali Loss: 1.2428423 Test Loss: 1.1064215
Validation loss decreased (1.243492 --> 1.242842).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.15874981880188
Epoch: 37, Steps: 63 | Train Loss: 0.7165305 Vali Loss: 1.2421439 Test Loss: 1.1063453
Validation loss decreased (1.242842 --> 1.242144).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.284287452697754
Epoch: 38, Steps: 63 | Train Loss: 0.7163556 Vali Loss: 1.2418973 Test Loss: 1.1061087
Validation loss decreased (1.242144 --> 1.241897).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.218400716781616
Epoch: 39, Steps: 63 | Train Loss: 0.7157766 Vali Loss: 1.2412324 Test Loss: 1.1060680
Validation loss decreased (1.241897 --> 1.241232).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.220913887023926
Epoch: 40, Steps: 63 | Train Loss: 0.7159312 Vali Loss: 1.2408892 Test Loss: 1.1056154
Validation loss decreased (1.241232 --> 1.240889).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.0143935680389404
Epoch: 41, Steps: 63 | Train Loss: 0.7151795 Vali Loss: 1.2402558 Test Loss: 1.1059476
Validation loss decreased (1.240889 --> 1.240256).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.1225922107696533
Epoch: 42, Steps: 63 | Train Loss: 0.7148465 Vali Loss: 1.2402177 Test Loss: 1.1057686
Validation loss decreased (1.240256 --> 1.240218).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 1.985173225402832
Epoch: 43, Steps: 63 | Train Loss: 0.7145874 Vali Loss: 1.2397977 Test Loss: 1.1057197
Validation loss decreased (1.240218 --> 1.239798).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 2.0771236419677734
Epoch: 44, Steps: 63 | Train Loss: 0.7144583 Vali Loss: 1.2389735 Test Loss: 1.1051779
Validation loss decreased (1.239798 --> 1.238973).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 1.872715950012207
Epoch: 45, Steps: 63 | Train Loss: 0.7140211 Vali Loss: 1.2392313 Test Loss: 1.1053722
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 2.2721498012542725
Epoch: 46, Steps: 63 | Train Loss: 0.7140493 Vali Loss: 1.2395964 Test Loss: 1.1054506
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.0464930534362793
Epoch: 47, Steps: 63 | Train Loss: 0.7130412 Vali Loss: 1.2390355 Test Loss: 1.1054652
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 1.7931103706359863
Epoch: 48, Steps: 63 | Train Loss: 0.7131019 Vali Loss: 1.2386732 Test Loss: 1.1051735
Validation loss decreased (1.238973 --> 1.238673).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 2.1377761363983154
Epoch: 49, Steps: 63 | Train Loss: 0.7127465 Vali Loss: 1.2388014 Test Loss: 1.1051185
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 1.8059475421905518
Epoch: 50, Steps: 63 | Train Loss: 0.7127435 Vali Loss: 1.2387502 Test Loss: 1.1051515
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.0595998764038086
Epoch: 51, Steps: 63 | Train Loss: 0.7130959 Vali Loss: 1.2384057 Test Loss: 1.1050421
Validation loss decreased (1.238673 --> 1.238406).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.2025744915008545
Epoch: 52, Steps: 63 | Train Loss: 0.7129366 Vali Loss: 1.2385908 Test Loss: 1.1049453
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.0829854011535645
Epoch: 53, Steps: 63 | Train Loss: 0.7128295 Vali Loss: 1.2385130 Test Loss: 1.1049354
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 1.9020185470581055
Epoch: 54, Steps: 63 | Train Loss: 0.7123037 Vali Loss: 1.2384548 Test Loss: 1.1049650
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.0980968475341797
Epoch: 55, Steps: 63 | Train Loss: 0.7125252 Vali Loss: 1.2379452 Test Loss: 1.1050079
Validation loss decreased (1.238406 --> 1.237945).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.317312240600586
Epoch: 56, Steps: 63 | Train Loss: 0.7121160 Vali Loss: 1.2385081 Test Loss: 1.1050581
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 1.8322670459747314
Epoch: 57, Steps: 63 | Train Loss: 0.7129321 Vali Loss: 1.2383664 Test Loss: 1.1049912
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 1.9677464962005615
Epoch: 58, Steps: 63 | Train Loss: 0.7123424 Vali Loss: 1.2380530 Test Loss: 1.1049006
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 1.9136817455291748
Epoch: 59, Steps: 63 | Train Loss: 0.7120983 Vali Loss: 1.2379048 Test Loss: 1.1048460
Validation loss decreased (1.237945 --> 1.237905).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 1.9942741394042969
Epoch: 60, Steps: 63 | Train Loss: 0.7112750 Vali Loss: 1.2381966 Test Loss: 1.1048216
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 1.9005484580993652
Epoch: 61, Steps: 63 | Train Loss: 0.7121047 Vali Loss: 1.2381698 Test Loss: 1.1048677
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 1.884073257446289
Epoch: 62, Steps: 63 | Train Loss: 0.7112622 Vali Loss: 1.2381802 Test Loss: 1.1048224
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 1.8624885082244873
Epoch: 63, Steps: 63 | Train Loss: 0.7121255 Vali Loss: 1.2376086 Test Loss: 1.1049044
Validation loss decreased (1.237905 --> 1.237609).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.157705068588257
Epoch: 64, Steps: 63 | Train Loss: 0.7114507 Vali Loss: 1.2379888 Test Loss: 1.1048094
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.266864776611328
Epoch: 65, Steps: 63 | Train Loss: 0.7122734 Vali Loss: 1.2373865 Test Loss: 1.1048255
Validation loss decreased (1.237609 --> 1.237386).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.349926471710205
Epoch: 66, Steps: 63 | Train Loss: 0.7117474 Vali Loss: 1.2377530 Test Loss: 1.1048441
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.091045618057251
Epoch: 67, Steps: 63 | Train Loss: 0.7113024 Vali Loss: 1.2379040 Test Loss: 1.1048082
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.3137192726135254
Epoch: 68, Steps: 63 | Train Loss: 0.7115307 Vali Loss: 1.2379527 Test Loss: 1.1048473
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 2.238556146621704
Epoch: 69, Steps: 63 | Train Loss: 0.7121254 Vali Loss: 1.2375917 Test Loss: 1.1047865
EarlyStopping counter: 4 out of 20
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.1180639266967773
Epoch: 70, Steps: 63 | Train Loss: 0.7121139 Vali Loss: 1.2374487 Test Loss: 1.1048055
EarlyStopping counter: 5 out of 20
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 1.8917875289916992
Epoch: 71, Steps: 63 | Train Loss: 0.7117649 Vali Loss: 1.2376292 Test Loss: 1.1047919
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.1501264572143555
Epoch: 72, Steps: 63 | Train Loss: 0.7116137 Vali Loss: 1.2376508 Test Loss: 1.1047301
EarlyStopping counter: 7 out of 20
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.1475167274475098
Epoch: 73, Steps: 63 | Train Loss: 0.7123276 Vali Loss: 1.2375624 Test Loss: 1.1048642
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.2400295734405518
Epoch: 74, Steps: 63 | Train Loss: 0.7117901 Vali Loss: 1.2372662 Test Loss: 1.1047364
Validation loss decreased (1.237386 --> 1.237266).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.0442943572998047
Epoch: 75, Steps: 63 | Train Loss: 0.7113703 Vali Loss: 1.2370905 Test Loss: 1.1047758
Validation loss decreased (1.237266 --> 1.237090).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 1.956592082977295
Epoch: 76, Steps: 63 | Train Loss: 0.7113131 Vali Loss: 1.2376702 Test Loss: 1.1047689
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.0577797889709473
Epoch: 77, Steps: 63 | Train Loss: 0.7110171 Vali Loss: 1.2376914 Test Loss: 1.1048101
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.2210307121276855
Epoch: 78, Steps: 63 | Train Loss: 0.7116449 Vali Loss: 1.2377872 Test Loss: 1.1047407
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.0162627696990967
Epoch: 79, Steps: 63 | Train Loss: 0.7115615 Vali Loss: 1.2371088 Test Loss: 1.1047143
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.354580879211426
Epoch: 80, Steps: 63 | Train Loss: 0.7114856 Vali Loss: 1.2368479 Test Loss: 1.1046594
Validation loss decreased (1.237090 --> 1.236848).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 1.8471028804779053
Epoch: 81, Steps: 63 | Train Loss: 0.7120742 Vali Loss: 1.2372453 Test Loss: 1.1047784
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.02705979347229
Epoch: 82, Steps: 63 | Train Loss: 0.7114117 Vali Loss: 1.2374578 Test Loss: 1.1047676
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.2451388835906982
Epoch: 83, Steps: 63 | Train Loss: 0.7114765 Vali Loss: 1.2368917 Test Loss: 1.1047987
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.2415196895599365
Epoch: 84, Steps: 63 | Train Loss: 0.7118141 Vali Loss: 1.2371097 Test Loss: 1.1046724
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 1.8742611408233643
Epoch: 85, Steps: 63 | Train Loss: 0.7115818 Vali Loss: 1.2373226 Test Loss: 1.1047894
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.212850332260132
Epoch: 86, Steps: 63 | Train Loss: 0.7113631 Vali Loss: 1.2373190 Test Loss: 1.1047729
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.3121912479400635
Epoch: 87, Steps: 63 | Train Loss: 0.7118883 Vali Loss: 1.2377751 Test Loss: 1.1047754
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 2.122769355773926
Epoch: 88, Steps: 63 | Train Loss: 0.7117011 Vali Loss: 1.2376900 Test Loss: 1.1047255
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.0675699710845947
Epoch: 89, Steps: 63 | Train Loss: 0.7120644 Vali Loss: 1.2373064 Test Loss: 1.1047906
EarlyStopping counter: 9 out of 20
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 1.9746332168579102
Epoch: 90, Steps: 63 | Train Loss: 0.7112525 Vali Loss: 1.2377148 Test Loss: 1.1047556
EarlyStopping counter: 10 out of 20
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 1.8817064762115479
Epoch: 91, Steps: 63 | Train Loss: 0.7119838 Vali Loss: 1.2377164 Test Loss: 1.1047598
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 1.8724288940429688
Epoch: 92, Steps: 63 | Train Loss: 0.7117927 Vali Loss: 1.2377268 Test Loss: 1.1046886
EarlyStopping counter: 12 out of 20
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.177262306213379
Epoch: 93, Steps: 63 | Train Loss: 0.7119963 Vali Loss: 1.2372434 Test Loss: 1.1047890
EarlyStopping counter: 13 out of 20
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 1.8382949829101562
Epoch: 94, Steps: 63 | Train Loss: 0.7113300 Vali Loss: 1.2377149 Test Loss: 1.1047540
EarlyStopping counter: 14 out of 20
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.326338291168213
Epoch: 95, Steps: 63 | Train Loss: 0.7117339 Vali Loss: 1.2375231 Test Loss: 1.1047609
EarlyStopping counter: 15 out of 20
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 1.7778725624084473
Epoch: 96, Steps: 63 | Train Loss: 0.7117267 Vali Loss: 1.2369802 Test Loss: 1.1048084
EarlyStopping counter: 16 out of 20
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.0526232719421387
Epoch: 97, Steps: 63 | Train Loss: 0.7121894 Vali Loss: 1.2372080 Test Loss: 1.1047028
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.1289353370666504
Epoch: 98, Steps: 63 | Train Loss: 0.7117304 Vali Loss: 1.2375743 Test Loss: 1.1047521
EarlyStopping counter: 18 out of 20
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 2.0406055450439453
Epoch: 99, Steps: 63 | Train Loss: 0.7119779 Vali Loss: 1.2374431 Test Loss: 1.1046683
EarlyStopping counter: 19 out of 20
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 1.8135178089141846
Epoch: 100, Steps: 63 | Train Loss: 0.7109717 Vali Loss: 1.2375439 Test Loss: 1.1047564
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 336_192_VanDerPol_ETTh1_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:1.104713797569275, mae:0.7685124278068542, rse:0.9981058239936829
