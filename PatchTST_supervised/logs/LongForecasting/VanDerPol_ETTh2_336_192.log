Args in experiment:
Namespace(W=0.1, activation='gelu', affine=0, alpha1=0.1, alpha2=0.1, alpha3=0.1, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=128, d_layers=1, d_model=16, data='ETTh2', data_path='ETTh2.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.3, e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='VanDerPol', model_id='336_192', moving_avg=25, n_heads=4, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 336_192_VanDerPol_ETTh2_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
Epoch: 1 cost time: 2.1522152423858643
Epoch: 1, Steps: 63 | Train Loss: 1.0906661 Vali Loss: 1.5575815 Test Loss: 3.2551491
Validation loss decreased (inf --> 1.557582).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.0038347244262695
Epoch: 2, Steps: 63 | Train Loss: 1.0512934 Vali Loss: 1.4879755 Test Loss: 3.1961997
Validation loss decreased (1.557582 --> 1.487975).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 1.9477276802062988
Epoch: 3, Steps: 63 | Train Loss: 1.0273960 Vali Loss: 1.4766989 Test Loss: 3.1923726
Validation loss decreased (1.487975 --> 1.476699).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 1.943572998046875
Epoch: 4, Steps: 63 | Train Loss: 1.0072080 Vali Loss: 1.4641722 Test Loss: 3.1735284
Validation loss decreased (1.476699 --> 1.464172).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 1.7935535907745361
Epoch: 5, Steps: 63 | Train Loss: 0.9838236 Vali Loss: 1.4515476 Test Loss: 3.1476171
Validation loss decreased (1.464172 --> 1.451548).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.100799083709717
Epoch: 6, Steps: 63 | Train Loss: 0.9593356 Vali Loss: 1.4357703 Test Loss: 3.1118171
Validation loss decreased (1.451548 --> 1.435770).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.1106081008911133
Epoch: 7, Steps: 63 | Train Loss: 0.9419035 Vali Loss: 1.4205978 Test Loss: 3.0801260
Validation loss decreased (1.435770 --> 1.420598).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.0682594776153564
Epoch: 8, Steps: 63 | Train Loss: 0.9228517 Vali Loss: 1.4071181 Test Loss: 3.0528641
Validation loss decreased (1.420598 --> 1.407118).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.090390920639038
Epoch: 9, Steps: 63 | Train Loss: 0.9099751 Vali Loss: 1.3924345 Test Loss: 3.0255454
Validation loss decreased (1.407118 --> 1.392434).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.111571788787842
Epoch: 10, Steps: 63 | Train Loss: 0.8973975 Vali Loss: 1.3795515 Test Loss: 3.0020051
Validation loss decreased (1.392434 --> 1.379552).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.081963539123535
Epoch: 11, Steps: 63 | Train Loss: 0.8861551 Vali Loss: 1.3698143 Test Loss: 2.9831188
Validation loss decreased (1.379552 --> 1.369814).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.4485890865325928
Epoch: 12, Steps: 63 | Train Loss: 0.8762855 Vali Loss: 1.3584527 Test Loss: 2.9659338
Validation loss decreased (1.369814 --> 1.358453).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.3279271125793457
Epoch: 13, Steps: 63 | Train Loss: 0.8681606 Vali Loss: 1.3496770 Test Loss: 2.9499936
Validation loss decreased (1.358453 --> 1.349677).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.2889487743377686
Epoch: 14, Steps: 63 | Train Loss: 0.8606616 Vali Loss: 1.3421968 Test Loss: 2.9364073
Validation loss decreased (1.349677 --> 1.342197).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.027841806411743
Epoch: 15, Steps: 63 | Train Loss: 0.8545106 Vali Loss: 1.3346097 Test Loss: 2.9235668
Validation loss decreased (1.342197 --> 1.334610).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.132028341293335
Epoch: 16, Steps: 63 | Train Loss: 0.8500426 Vali Loss: 1.3286788 Test Loss: 2.9134986
Validation loss decreased (1.334610 --> 1.328679).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.018138885498047
Epoch: 17, Steps: 63 | Train Loss: 0.8451181 Vali Loss: 1.3229736 Test Loss: 2.9032459
Validation loss decreased (1.328679 --> 1.322974).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.0335419178009033
Epoch: 18, Steps: 63 | Train Loss: 0.8399532 Vali Loss: 1.3189017 Test Loss: 2.8949986
Validation loss decreased (1.322974 --> 1.318902).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.102067232131958
Epoch: 19, Steps: 63 | Train Loss: 0.8353612 Vali Loss: 1.3144513 Test Loss: 2.8874960
Validation loss decreased (1.318902 --> 1.314451).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 1.894482135772705
Epoch: 20, Steps: 63 | Train Loss: 0.8320745 Vali Loss: 1.3097981 Test Loss: 2.8804593
Validation loss decreased (1.314451 --> 1.309798).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.5086076259613037
Epoch: 21, Steps: 63 | Train Loss: 0.8279868 Vali Loss: 1.3065253 Test Loss: 2.8739643
Validation loss decreased (1.309798 --> 1.306525).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.253037214279175
Epoch: 22, Steps: 63 | Train Loss: 0.8266062 Vali Loss: 1.3031584 Test Loss: 2.8685818
Validation loss decreased (1.306525 --> 1.303158).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.217750072479248
Epoch: 23, Steps: 63 | Train Loss: 0.8232222 Vali Loss: 1.3004675 Test Loss: 2.8637733
Validation loss decreased (1.303158 --> 1.300467).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.381603240966797
Epoch: 24, Steps: 63 | Train Loss: 0.8210380 Vali Loss: 1.2982625 Test Loss: 2.8587532
Validation loss decreased (1.300467 --> 1.298262).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.1577210426330566
Epoch: 25, Steps: 63 | Train Loss: 0.8191515 Vali Loss: 1.2955984 Test Loss: 2.8549533
Validation loss decreased (1.298262 --> 1.295598).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.3432135581970215
Epoch: 26, Steps: 63 | Train Loss: 0.8172419 Vali Loss: 1.2938133 Test Loss: 2.8515911
Validation loss decreased (1.295598 --> 1.293813).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.314500093460083
Epoch: 27, Steps: 63 | Train Loss: 0.8165443 Vali Loss: 1.2918215 Test Loss: 2.8480277
Validation loss decreased (1.293813 --> 1.291821).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.6204559803009033
Epoch: 28, Steps: 63 | Train Loss: 0.8123151 Vali Loss: 1.2894776 Test Loss: 2.8451824
Validation loss decreased (1.291821 --> 1.289478).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.547060012817383
Epoch: 29, Steps: 63 | Train Loss: 0.8120211 Vali Loss: 1.2892793 Test Loss: 2.8423438
Validation loss decreased (1.289478 --> 1.289279).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.322869300842285
Epoch: 30, Steps: 63 | Train Loss: 0.8125331 Vali Loss: 1.2867053 Test Loss: 2.8401096
Validation loss decreased (1.289279 --> 1.286705).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.342247247695923
Epoch: 31, Steps: 63 | Train Loss: 0.8111663 Vali Loss: 1.2864623 Test Loss: 2.8379030
Validation loss decreased (1.286705 --> 1.286462).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.290760040283203
Epoch: 32, Steps: 63 | Train Loss: 0.8096391 Vali Loss: 1.2848760 Test Loss: 2.8360298
Validation loss decreased (1.286462 --> 1.284876).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.1353697776794434
Epoch: 33, Steps: 63 | Train Loss: 0.8088833 Vali Loss: 1.2845455 Test Loss: 2.8340704
Validation loss decreased (1.284876 --> 1.284546).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.220092296600342
Epoch: 34, Steps: 63 | Train Loss: 0.8076169 Vali Loss: 1.2837126 Test Loss: 2.8325784
Validation loss decreased (1.284546 --> 1.283713).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.14188551902771
Epoch: 35, Steps: 63 | Train Loss: 0.8066001 Vali Loss: 1.2828833 Test Loss: 2.8311660
Validation loss decreased (1.283713 --> 1.282883).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.1383979320526123
Epoch: 36, Steps: 63 | Train Loss: 0.8047288 Vali Loss: 1.2822568 Test Loss: 2.8299670
Validation loss decreased (1.282883 --> 1.282257).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.4201180934906006
Epoch: 37, Steps: 63 | Train Loss: 0.8050153 Vali Loss: 1.2816935 Test Loss: 2.8288884
Validation loss decreased (1.282257 --> 1.281693).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.023245334625244
Epoch: 38, Steps: 63 | Train Loss: 0.8050498 Vali Loss: 1.2803457 Test Loss: 2.8278468
Validation loss decreased (1.281693 --> 1.280346).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.4179563522338867
Epoch: 39, Steps: 63 | Train Loss: 0.8054324 Vali Loss: 1.2801160 Test Loss: 2.8267610
Validation loss decreased (1.280346 --> 1.280116).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.3341641426086426
Epoch: 40, Steps: 63 | Train Loss: 0.8049616 Vali Loss: 1.2801722 Test Loss: 2.8261395
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 2.128404140472412
Epoch: 41, Steps: 63 | Train Loss: 0.8040386 Vali Loss: 1.2796954 Test Loss: 2.8250473
Validation loss decreased (1.280116 --> 1.279695).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 2.3813869953155518
Epoch: 42, Steps: 63 | Train Loss: 0.8025363 Vali Loss: 1.2792434 Test Loss: 2.8245540
Validation loss decreased (1.279695 --> 1.279243).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 2.1887495517730713
Epoch: 43, Steps: 63 | Train Loss: 0.8035481 Vali Loss: 1.2790604 Test Loss: 2.8239148
Validation loss decreased (1.279243 --> 1.279060).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 1.935415506362915
Epoch: 44, Steps: 63 | Train Loss: 0.8034393 Vali Loss: 1.2787683 Test Loss: 2.8234677
Validation loss decreased (1.279060 --> 1.278768).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 2.307039260864258
Epoch: 45, Steps: 63 | Train Loss: 0.8032508 Vali Loss: 1.2784812 Test Loss: 2.8228786
Validation loss decreased (1.278768 --> 1.278481).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 1.9352450370788574
Epoch: 46, Steps: 63 | Train Loss: 0.8028023 Vali Loss: 1.2784514 Test Loss: 2.8223660
Validation loss decreased (1.278481 --> 1.278451).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 2.1035401821136475
Epoch: 47, Steps: 63 | Train Loss: 0.8010743 Vali Loss: 1.2781111 Test Loss: 2.8217452
Validation loss decreased (1.278451 --> 1.278111).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 2.0709757804870605
Epoch: 48, Steps: 63 | Train Loss: 0.8020793 Vali Loss: 1.2777754 Test Loss: 2.8213868
Validation loss decreased (1.278111 --> 1.277775).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 1.9267585277557373
Epoch: 49, Steps: 63 | Train Loss: 0.8019405 Vali Loss: 1.2770197 Test Loss: 2.8210580
Validation loss decreased (1.277775 --> 1.277020).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 1.9055452346801758
Epoch: 50, Steps: 63 | Train Loss: 0.8033328 Vali Loss: 1.2774981 Test Loss: 2.8210764
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 2.0710737705230713
Epoch: 51, Steps: 63 | Train Loss: 0.8031020 Vali Loss: 1.2774639 Test Loss: 2.8206179
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 2.0938127040863037
Epoch: 52, Steps: 63 | Train Loss: 0.8003197 Vali Loss: 1.2772307 Test Loss: 2.8204439
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 2.3048415184020996
Epoch: 53, Steps: 63 | Train Loss: 0.8005253 Vali Loss: 1.2769526 Test Loss: 2.8201637
Validation loss decreased (1.277020 --> 1.276953).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 2.207857847213745
Epoch: 54, Steps: 63 | Train Loss: 0.7991397 Vali Loss: 1.2765081 Test Loss: 2.8197553
Validation loss decreased (1.276953 --> 1.276508).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 2.1737372875213623
Epoch: 55, Steps: 63 | Train Loss: 0.8029748 Vali Loss: 1.2764101 Test Loss: 2.8194776
Validation loss decreased (1.276508 --> 1.276410).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 2.135059118270874
Epoch: 56, Steps: 63 | Train Loss: 0.8015933 Vali Loss: 1.2761281 Test Loss: 2.8196428
Validation loss decreased (1.276410 --> 1.276128).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 2.1691224575042725
Epoch: 57, Steps: 63 | Train Loss: 0.8003945 Vali Loss: 1.2769341 Test Loss: 2.8194542
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 2.192880868911743
Epoch: 58, Steps: 63 | Train Loss: 0.8014945 Vali Loss: 1.2766929 Test Loss: 2.8192110
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 2.3943562507629395
Epoch: 59, Steps: 63 | Train Loss: 0.8019328 Vali Loss: 1.2766116 Test Loss: 2.8192616
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 2.174100160598755
Epoch: 60, Steps: 63 | Train Loss: 0.8005441 Vali Loss: 1.2768424 Test Loss: 2.8190930
EarlyStopping counter: 4 out of 20
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 2.032526969909668
Epoch: 61, Steps: 63 | Train Loss: 0.8013937 Vali Loss: 1.2766848 Test Loss: 2.8191197
EarlyStopping counter: 5 out of 20
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 2.319518566131592
Epoch: 62, Steps: 63 | Train Loss: 0.8014259 Vali Loss: 1.2758162 Test Loss: 2.8189270
Validation loss decreased (1.276128 --> 1.275816).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 2.4096078872680664
Epoch: 63, Steps: 63 | Train Loss: 0.8008067 Vali Loss: 1.2757931 Test Loss: 2.8188014
Validation loss decreased (1.275816 --> 1.275793).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 2.3510446548461914
Epoch: 64, Steps: 63 | Train Loss: 0.8011414 Vali Loss: 1.2764815 Test Loss: 2.8188217
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 2.0469319820404053
Epoch: 65, Steps: 63 | Train Loss: 0.8013641 Vali Loss: 1.2764746 Test Loss: 2.8188190
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 2.08767032623291
Epoch: 66, Steps: 63 | Train Loss: 0.8010727 Vali Loss: 1.2763383 Test Loss: 2.8188198
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 2.086423635482788
Epoch: 67, Steps: 63 | Train Loss: 0.8019079 Vali Loss: 1.2757704 Test Loss: 2.8188894
Validation loss decreased (1.275793 --> 1.275770).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 2.030630588531494
Epoch: 68, Steps: 63 | Train Loss: 0.8011055 Vali Loss: 1.2757841 Test Loss: 2.8184183
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 1.9960343837738037
Epoch: 69, Steps: 63 | Train Loss: 0.8015206 Vali Loss: 1.2762189 Test Loss: 2.8184388
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 2.0968849658966064
Epoch: 70, Steps: 63 | Train Loss: 0.8010376 Vali Loss: 1.2763412 Test Loss: 2.8186531
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 2.418903350830078
Epoch: 71, Steps: 63 | Train Loss: 0.8015106 Vali Loss: 1.2757181 Test Loss: 2.8185430
Validation loss decreased (1.275770 --> 1.275718).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 2.1064517498016357
Epoch: 72, Steps: 63 | Train Loss: 0.8005027 Vali Loss: 1.2762575 Test Loss: 2.8186893
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 2.329836845397949
Epoch: 73, Steps: 63 | Train Loss: 0.8030323 Vali Loss: 1.2762668 Test Loss: 2.8181925
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 2.363665819168091
Epoch: 74, Steps: 63 | Train Loss: 0.7996810 Vali Loss: 1.2763942 Test Loss: 2.8183801
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 2.3400282859802246
Epoch: 75, Steps: 63 | Train Loss: 0.7999058 Vali Loss: 1.2761540 Test Loss: 2.8183515
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 2.155374526977539
Epoch: 76, Steps: 63 | Train Loss: 0.7992481 Vali Loss: 1.2762454 Test Loss: 2.8184421
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 2.0436089038848877
Epoch: 77, Steps: 63 | Train Loss: 0.8001059 Vali Loss: 1.2758973 Test Loss: 2.8179848
EarlyStopping counter: 6 out of 20
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 2.2634010314941406
Epoch: 78, Steps: 63 | Train Loss: 0.7999713 Vali Loss: 1.2762834 Test Loss: 2.8185527
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 2.1599998474121094
Epoch: 79, Steps: 63 | Train Loss: 0.8002185 Vali Loss: 1.2762820 Test Loss: 2.8183537
EarlyStopping counter: 8 out of 20
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 2.007554531097412
Epoch: 80, Steps: 63 | Train Loss: 0.8016895 Vali Loss: 1.2760596 Test Loss: 2.8181908
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 2.098720073699951
Epoch: 81, Steps: 63 | Train Loss: 0.8007012 Vali Loss: 1.2756917 Test Loss: 2.8183732
Validation loss decreased (1.275718 --> 1.275692).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 2.1825339794158936
Epoch: 82, Steps: 63 | Train Loss: 0.8007181 Vali Loss: 1.2760781 Test Loss: 2.8182552
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 2.0177483558654785
Epoch: 83, Steps: 63 | Train Loss: 0.8006155 Vali Loss: 1.2761592 Test Loss: 2.8182073
EarlyStopping counter: 2 out of 20
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 2.0331361293792725
Epoch: 84, Steps: 63 | Train Loss: 0.8015288 Vali Loss: 1.2763841 Test Loss: 2.8181918
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 2.3491106033325195
Epoch: 85, Steps: 63 | Train Loss: 0.8019148 Vali Loss: 1.2756889 Test Loss: 2.8183630
Validation loss decreased (1.275692 --> 1.275689).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 2.478607416152954
Epoch: 86, Steps: 63 | Train Loss: 0.8009145 Vali Loss: 1.2761781 Test Loss: 2.8183582
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 2.0897016525268555
Epoch: 87, Steps: 63 | Train Loss: 0.8006661 Vali Loss: 1.2756791 Test Loss: 2.8181074
Validation loss decreased (1.275689 --> 1.275679).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 1.9188482761383057
Epoch: 88, Steps: 63 | Train Loss: 0.8015876 Vali Loss: 1.2756087 Test Loss: 2.8182302
Validation loss decreased (1.275679 --> 1.275609).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 2.088357448577881
Epoch: 89, Steps: 63 | Train Loss: 0.7993946 Vali Loss: 1.2760621 Test Loss: 2.8182952
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 2.0347423553466797
Epoch: 90, Steps: 63 | Train Loss: 0.8000026 Vali Loss: 1.2763005 Test Loss: 2.8180950
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 2.037168025970459
Epoch: 91, Steps: 63 | Train Loss: 0.8008485 Vali Loss: 1.2759784 Test Loss: 2.8181591
EarlyStopping counter: 3 out of 20
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 2.1074512004852295
Epoch: 92, Steps: 63 | Train Loss: 0.8003499 Vali Loss: 1.2761961 Test Loss: 2.8181596
EarlyStopping counter: 4 out of 20
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 2.1245357990264893
Epoch: 93, Steps: 63 | Train Loss: 0.8005379 Vali Loss: 1.2762152 Test Loss: 2.8183353
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 2.05383038520813
Epoch: 94, Steps: 63 | Train Loss: 0.8016527 Vali Loss: 1.2760339 Test Loss: 2.8180175
EarlyStopping counter: 6 out of 20
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 2.168726921081543
Epoch: 95, Steps: 63 | Train Loss: 0.8020219 Vali Loss: 1.2755436 Test Loss: 2.8182743
Validation loss decreased (1.275609 --> 1.275544).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 2.2117080688476562
Epoch: 96, Steps: 63 | Train Loss: 0.7991490 Vali Loss: 1.2760946 Test Loss: 2.8181214
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 2.056021213531494
Epoch: 97, Steps: 63 | Train Loss: 0.8011329 Vali Loss: 1.2762704 Test Loss: 2.8182855
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 2.1942129135131836
Epoch: 98, Steps: 63 | Train Loss: 0.7994459 Vali Loss: 1.2755407 Test Loss: 2.8180876
Validation loss decreased (1.275544 --> 1.275541).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 1.8687412738800049
Epoch: 99, Steps: 63 | Train Loss: 0.8003892 Vali Loss: 1.2760646 Test Loss: 2.8178868
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 2.2305917739868164
Epoch: 100, Steps: 63 | Train Loss: 0.8008835 Vali Loss: 1.2762011 Test Loss: 2.8181698
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : 336_192_VanDerPol_ETTh2_ftM_sl336_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:2.818168878555298, mae:1.4311161041259766, rse:1.3461239337921143
